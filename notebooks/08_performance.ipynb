{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Topics\n",
    "- Why Julia is fast\n",
    "- LLVM compiler\n",
    "- Parallellization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Julia fast?\n",
    "- Rich type information, provided naturally by multiple dispatch\n",
    "- Aggressive code specialization against run-time types\n",
    "- JIT compilation using the LLVM compiler framework\n",
    "\n",
    "In short, Julia is designated from the beginning to be fast. Not vice versa.\n",
    "\n",
    "See the [scientific paper](https://arxiv.org/pdf/1209.5145v1.pdf) behind Julia, if you want to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Levels of parallellism\n",
    "1. Instruction level parallellism\n",
    "2. Vector instructions (see `Bonus_simd-vectorization.pynb` if you are interested)\n",
    "3. **Threading** (shared-memory)\n",
    "4. **Distributed**\n",
    "5. Accelerators (e.g., GPGPU; *not covered here*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced: A (very short) introduction to the interiors of Julia compiler\n",
    "\n",
    "Let's stop treating our tools like blackboxes. Let's see what the compiler herself is thinking about our code with `using InteractiveUtils`.\n",
    "\n",
    "1. `@code_lowered`\n",
    "2. `@code_typed` and `@code_warntype`\n",
    "3. `@code_llvm`\n",
    "4. `@code_native`\n",
    "\n",
    "See [slides](https://slides.com/valentinchuravy/julia-parallelism) by Valentin Churavy, for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function mysum(A)\n",
    "    acc = zero(eltype(A))\n",
    "    for a in A\n",
    "        acc += a\n",
    "    end\n",
    "    return acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using InteractiveUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@code_lowered mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@code_typed mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "@code_llvm mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@code_native mysum(ones(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About global scope\n",
    "So what does the previous machine code actually mean? Well, in practise:\n",
    "\n",
    "A global variable might have its value, and therefore its type, change at any given point. This makes it difficult/nigh impossible for the compiler to reason about/optimize code using global variables.\n",
    "\n",
    "Julia uses functions as its compilation unit and any code that is performance critical or being benchmarked should be inside a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo: Giving hints to the compiler \n",
    "Let's see what we can do with our previously defined `laplacian` function. \n",
    "\n",
    "For some aggressive cases we can provide the JIT-compiler `@inbounds` macro hinting that there is no need to check array bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Lets re-define our previous Laplacians (from 05_ notebook)\n",
    "function laplacian_bad(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ir = 2:nr-1, ic = 2:nc-1 # bad loop nesting order\n",
    "        lap_x[ir,ic] =\n",
    "            (x[ir+1,ic] + x[ir-1,ic] +\n",
    "            x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "    end\n",
    "end\n",
    "\n",
    "#In this version, the two loops are nested properly:\n",
    "function laplacian_good(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ic = 2:nc-1, ir = 2:nr-1 # good loop nesting order\n",
    "        lap_x[ir,ic] =\n",
    "            (x[ir+1,ic] + x[ir-1,ic] +\n",
    "            x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A way to increase the speed is to remove the array bounds checking, using the macro @inbounds:\n",
    "function laplacian_good_nocheck(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ic = 2:nc-1\n",
    "        for ir = 2:nr-1 # good loop nesting order\n",
    "            @inbounds begin lap_x[ir,ic] = # no array bounds checking\n",
    "                (x[ir+1,ic] +  x[ir-1,ic] +\n",
    "                x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using Printf #evaluate me to get printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function main_test(nr, nc)\n",
    "    field = zeros(nr, nc)\n",
    "    for ic = 1:nc, ir = 1:nr\n",
    "        if ir == 1 || ic == 1 || ir == nr || ic == nc\n",
    "            field[ir,ic] = 1.0\n",
    "        end\n",
    "    end\n",
    "    lap_field = zeros(size(field))\n",
    "\n",
    "    time = @elapsed laplacian_bad(lap_field, field)\n",
    "    @printf \"laplacian_bad:          %.3f s\\n\" time\n",
    "    \n",
    "    time = @elapsed laplacian_good(lap_field, field)\n",
    "    @printf \"laplacian_good:         %.3f s\\n\" time\n",
    "    \n",
    "    time = @elapsed laplacian_good_nocheck(lap_field, field)\n",
    "    @printf \"laplacian_good_nocheck: %.3f s\\n\" time\n",
    "end\n",
    "\n",
    "main_test(10^4, 10^4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Threading (experimental)\n",
    "Julia threading model is based on a fork-join approach and is still considered experimental.\n",
    "\n",
    "Fork-join describes the control flow that a group of threads undergoes. Execution is then forked and an anonymous function is ran across all threads.\n",
    "\n",
    "All threads have to join together and serial execution continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Threading in practise\n",
    "The number of threads Julia starts up with is controlled by an environment variable called `JULIA_NUM_THREADS`. Now, let's start up Julia with 4 threads:\n",
    "\n",
    "```bash\n",
    "export JULIA_NUM_THREADS=4\n",
    "julia\n",
    "```\n",
    "\n",
    "NOTE: this does not work in the notebook environment because the kernel is automatically loaded with only 1 thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Base.Threads\n",
    "nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using threads\n",
    "\n",
    "```julia\n",
    "@threads for id in 1:nthreads()\n",
    "    #each thread does something\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = zeros(10)\n",
    "@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Advanced: Threaded sum\n",
    "Here is a more complex example of threaded sum from https://github.com/stevengj/18S096/blob/master/lectures/lecture5/Parallelism.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "function threaded_sum(arr)\n",
    "   @assert length(arr) % nthreads() == 0\n",
    "    \n",
    "   let results = zeros(eltype(arr), nthreads())\n",
    "       @threads for tid in 1:nthreads()\n",
    "           # split work\n",
    "           acc = zero(eltype(arr))\n",
    "           len = div(length(arr), nthreads())\n",
    "           domain = ((tid-1)*len +1):tid*len\n",
    "           @inbounds for i in domain\n",
    "               acc += arr[i]    \n",
    "           end\n",
    "           results[tid] = acc\n",
    "       end\n",
    "       sum(results)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed computing \n",
    "Distributed processing uses individual processes that communicate with each other. In this case, data movement and communication is explicit!\n",
    "\n",
    "Julia supports various forms of distributed computing. \n",
    "- **A native master-worker system based on remote procedure calls**\n",
    "- MPI through [MPI.jl](https://github.com/JuliaParallel/MPI.jl)\n",
    "- [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Master-Worker model\n",
    "We need to launch Julia with \n",
    "```bash\n",
    "julia -p 4\n",
    "```\n",
    "then inside Julia you can check\n",
    "```julia\n",
    "nprocs()\n",
    "workers()\n",
    "```\n",
    "which should print `5` and `[2,3,4,5]`. \n",
    "\n",
    "Why 5, you ask? Because *\"worker 1\"* is the *\"boss\"*. And bosses don't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Functions (and everything used by workers) needs to be explicitly declared for all:\n",
    "```julia\n",
    "@everywhere g(x) = 2x\n",
    "```\n",
    "Only then can we send the job to somebody else and fetch the result\n",
    "```julia\n",
    "remotecall_fetch(g, 3, 2.0)\n",
    "```\n",
    "Here we fetch the result of `g` of worker `3` applied to a value of `2.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use `@everywhere` to execute a top-level block on each process\n",
    "```julia\n",
    "@everywhere begin\n",
    "    using Test\n",
    "    include(\"src.jl\")\n",
    "end\n",
    "```\n",
    "Define variables on all processes\n",
    "```julia\n",
    "@everywhere bar = 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `@distributed` as a shortcut \n",
    "A parallel for loop of the form (from `using Distributed`):\n",
    "```julia\n",
    "@distributed [reducer] for var = range\n",
    "    body\n",
    "end\n",
    "```\n",
    "The specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, `@distributed` performs local reductions on each worker with a final reduction on the calling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that without a reducer function, `@distributed` executes asynchronously, i.e., it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with `@sync`, like :\n",
    "```julia\n",
    "@sync @distributed for var = range\n",
    "      body\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using Distributed\n",
    "\n",
    "nheads = @distributed (+) for i=1:200000000\n",
    "  Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pmap for unbalanced load\n",
    "In some cases no reduction operator is needed, and we merely wish to apply a function to all integers in some range. This is another useful operation called parallel map. \n",
    "\n",
    "For example, we could compute the singular values of several large random matrices in parallel as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra #loading svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(1000,1000) for i=1:10]\n",
    "pmap(svd, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pmap()` is designed for the case where each function call does a large amount of work. In contrast, `@distributed for` can handle situations where each iteration is tiny, perhaps merely summing two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: General optimization tricks\n",
    "\n",
    "- Write functions!\n",
    "- Avoid global variables\n",
    "    - A global variable might have its value, (and type) change at any given point. This makes it hard for the compiler to optimize."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
